{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kudzai Sibanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import distributions as dist\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Carlos\\Onedrive\\Desktop\\AML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             Id                                             Review  Label\n",
       "0            0                               good and interesting      5\n",
       "1            1  This class is very helpful to me. Currently, I...      5\n",
       "2            2  like!Prof and TAs are helpful and the discussi...      5\n",
       "3            3  Easy to follow and includes a lot basic and im...      5\n",
       "4            4  Really nice teacher!I could got the point eazl...      4\n",
       "...        ...                                                ...    ...\n",
       "107013  107013  Trendy topic with talks from expertises in the...      4\n",
       "107014  107014  Wonderful! Simple and clear language, good ins...      5\n",
       "107015  107015   an interesting and fun course. thanks. dr quincy      5\n",
       "107016  107016  very broad perspective, up to date information...      4\n",
       "107017  107017  An informative course on the social and financ...      4\n",
       "\n",
       "[107018 rows x 3 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r'reviews.xlsx',encoding = 'latin-1',sep =\"|\")\n",
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Carlos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [] \n",
    "  \n",
    "for i in range(0,107018 ): \n",
    "    text = re.sub('[^a-z A-Z]','' , data['Review'][i]) \n",
    "    text = text.lower() \n",
    "    text = text.split() \n",
    "    ps = PorterStemmer() \n",
    "    text = ''.join(text) \n",
    "    vocab.append(text) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = MultiLabelBinarizer()\n",
    "Xd = vec.fit_transform(vocab) #transform into binary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable definitions\n",
    "data['Review'] = data['Review'].astype(str) #convert to string format\n",
    "Yd = data['Label']\n",
    "N = Xd.shape[0]  #total number of points \n",
    "M = np.c_[Xd, Yd] #joining reviews and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xd,Yd, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique words in reviews data\n",
    "vocabulari = Xd.shape[1]\n",
    "vocabulari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES CALCULATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES FUNCTION\n",
    "def NaiveBayes (likelihood, prior):\n",
    "    return(likelihood * prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1:  2469\n",
      "Label 2:  2251\n",
      "Label 3:  5071\n",
      "Label 4:  18054\n",
      "Label 5:  79173\n"
     ]
    }
   ],
   "source": [
    "#sums of features in each label/rating class\n",
    "N_1 = (Yd==1).sum()\n",
    "print('Label 1: ',N_1)\n",
    "N_2 = (Yd==2).sum()\n",
    "print('Label 2: ',N_2)\n",
    "N_3 = (Yd==3).sum()\n",
    "print('Label 3: ',N_3)\n",
    "N_4 = (Yd==4).sum()\n",
    "print('Label 4: ',N_4)\n",
    "N_5 = (Yd==5).sum()\n",
    "print('Label 5: ',N_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of times a feature/word is observed in each class\n",
    "N_j1 = np.sum(M[Yd==1] [:,:Xd.shape[1]] ,axis=0)\n",
    "N_j2 = np.sum(M[Yd==2] [:,:Xd.shape[1]] ,axis=0)\n",
    "N_j3 = np.sum(M[Yd==3] [:,:Xd.shape[1]] ,axis=0)\n",
    "N_j4 = np.sum(M[Yd==4] [:,:Xd.shape[1]] ,axis=0)\n",
    "N_j5 = np.sum(M[Yd==5] [:,:Xd.shape[1]] ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilities of a feature belonging to each of the classes\n",
    "π_1 = N_1/N\n",
    "π_2 = N_2/N\n",
    "π_3 = N_3/N\n",
    "π_4 = N_4/N\n",
    "π_5 = N_5/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the likelihood for each class with laplace smoothing added\n",
    "likelihood_1 = (np.product(N_j1) + 1)/(N_1 + abs(vocabulari))\n",
    "likelihood_2 = (np.product(N_j2) + 1)/(N_2 + abs(vocabulari))\n",
    "likelihood_3 = (np.product(N_j3) + 1)/(N_3 + abs(vocabulari))\n",
    "likelihood_4 = (np.product(N_j4) + 1)/(N_4 + abs(vocabulari))\n",
    "likelihood_5 = (np.product(N_j5) + 1)/(N_5 + abs(vocabulari))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying for each class\n",
    "Class_Label1 = NaiveBayes(likelihood_1, π_1)\n",
    "Class_Label2 = NaiveBayes(likelihood_2, π_2)\n",
    "Class_Label3 = NaiveBayes(likelihood_3, π_3)\n",
    "Class_Label4 = NaiveBayes(likelihood_4, π_4)\n",
    "Class_Label5 = NaiveBayes(likelihood_5, π_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = NaiveBayes(likelihood_1, π_1)\n",
    "model2 = NaiveBayes(likelihood_2, π_2)\n",
    "model3 = NaiveBayes(likelihood_3, π_3)\n",
    "model4 = NaiveBayes(likelihood_4, π_4)\n",
    "model5 = NaiveBayes(likelihood_5, π_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes model accuracy(in %): 74.09456176415623\n"
     ]
    }
   ],
   "source": [
    "print(\" Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    19824\n",
      "4     4522\n",
      "3     1275\n",
      "1      599\n",
      "2      535\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#test values\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73942565 0.73942565 0.73942565 0.73947172 0.73940942]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation training data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(nb, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74098299 0.74098299 0.74098299 0.74098299 0.74079611]\n"
     ]
    }
   ],
   "source": [
    "#cross validation testing data\n",
    "scores = cross_val_score(nb, X_test, y_test, cv=5, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
